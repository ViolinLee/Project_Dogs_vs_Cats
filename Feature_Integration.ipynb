{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import numpy as np\n",
    "\n",
    "base_dir = '/home/leechan/Documents/Capstone_Dog vs. Cats/Project_Dogs_vs_Cats/Dataset_Dogs_vs_Cats/base'\n",
    "train2 = os.path.join(base_dir, 'train2')\n",
    "if not os.path.isdir(train2):\n",
    "    os.mkdir(train2)\n",
    "\n",
    "test2 = '/home/leechan/Documents/Capstone_Dog vs. Cats/Project_Dogs_vs_Cats/Dataset_Dogs_vs_Cats/base/test_dir'\n",
    "\n",
    "train2_cats = os.path.join(train2, 'cats')\n",
    "if not os.path.isdir(train2_cats):\n",
    "    os.mkdir(train2_cats)\n",
    "\n",
    "train2_dogs = os.path.join(train2, 'dogs')\n",
    "if not os.path.isdir(train2_dogs):\n",
    "    os.mkdir(train2_dogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "origin_train_dir = '/home/leechan/Documents/Capstone_Dog vs. Cats/Project_Dogs_vs_Cats/Dataset_Dogs_vs_Cats/train'\n",
    "\n",
    "filenames = ['cat.{}.jpg'.format(i) for i in range(12500)]\n",
    "for filename in filenames:\n",
    "    src = os.path.join(origin_train_dir, filename)\n",
    "    dst = os.path.join(train2_cats, filename)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "filenames = ['dog.{}.jpg'.format(i) for i in range(12500)]\n",
    "for filename in filenames:\n",
    "    src = os.path.join(origin_train_dir, filename)\n",
    "    dst = os.path.join(train2_dogs, filename)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model,Input\n",
    "from keras.layers import GlobalAveragePooling2D, Lambda \n",
    "from keras.applications import ResNet50, InceptionV3, Xception, resnet50, inception_v3, xception\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import h5py\n",
    "\n",
    "def write_gap(MODEL, image_size, lambda_func=None):\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = Input((height, width, 3))\n",
    "    x = input_tensor\n",
    "    if lambda_func:\n",
    "        x = Lambda(lambda_func)(x)\n",
    "    \n",
    "    base_model = MODEL(input_tensor=x, weights='imagenet', include_top=False)\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "    \n",
    "    gen = ImageDataGenerator()\n",
    "    batch_size = 15\n",
    "    \n",
    "    train_generator = gen.flow_from_directory(train2, image_size, shuffle=False, batch_size=batch_size, class_mode='binary')\n",
    "    test_generator = gen.flow_from_directory(test2, image_size, shuffle=False, batch_size=batch_size, class_mode=None)\n",
    "    \n",
    "    train = np.zeros(shape=(25000, 2048))\n",
    "    test = np.zeros(shape=(12500, 2048))\n",
    "    label = np.zeros(shape=(25000,))\n",
    "    \n",
    "    i = 0\n",
    "    j = 0\n",
    "    for train_inputs_batch, train_labels_batch in train_generator:\n",
    "        train_features_batch = model.predict(train_inputs_batch)\n",
    "        train[i * batch_size : (i + 1) * batch_size] = train_features_batch\n",
    "        label[i * batch_size : (i + 1) * batch_size] = train_labels_batch\n",
    "        \n",
    "        i += 1\n",
    "        if i * batch_size >= 25000:\n",
    "            break\n",
    "    \n",
    "    for test_inputs_batch in test_generator:\n",
    "        test_features_batch = model.predict(test_inputs_batch)\n",
    "        test[j * batch_size : (j + 1) * batch_size] = test_features_batch\n",
    "        \n",
    "        j += 1\n",
    "        if j * batch_size >= 12500:\n",
    "            break\n",
    "\n",
    "    with h5py.File(\"gap_%s.h5\"%MODEL.__name__) as h:        \n",
    "        h.create_dataset(\"train\", data=train)\n",
    "        h.create_dataset(\"label\", data=label)\n",
    "        h.create_dataset(\"test\", data=test)\n",
    "        \n",
    "        \n",
    "write_gap(ResNet50, (224, 224), resnet50.preprocess_input)\n",
    "write_gap(InceptionV3, (299, 299), inception_v3.preprocess_input)\n",
    "write_gap(Xception, (299, 299), xception.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2048)\n",
      "(12500, 2048)\n",
      "(25000,)\n",
      "(25000, 2048)\n",
      "(12500, 2048)\n",
      "(25000,)\n",
      "(25000, 2048)\n",
      "(12500, 2048)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "for filename in [\"gap_ResNet50.h5\", \"gap_Xception.h5\", \"gap_InceptionV3.h5\"]:\n",
    "    with h5py.File(\"gap_ResNet50.h5\", 'r') as h:\n",
    "\n",
    "        print(np.array(h['train']).shape)\n",
    "        print(np.array(h['test']).shape)\n",
    "        print(np.array(h['label']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 4096)\n",
      "(12500, 4096)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "#np.random.seed(2017)\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "for filename in [\"gap_Xception.h5\", \"gap_InceptionV3.h5\"]:\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        X_train.append(np.array(h['train']))\n",
    "        X_test.append(np.array(h['test']))\n",
    "        y_train = np.array(h['label'])\n",
    "\n",
    "X_train = np.concatenate(X_train, axis=1)\n",
    "X_test = np.concatenate(X_test, axis=1)\n",
    "\n",
    "print(np.array(X_train).shape)\n",
    "print(np.array(X_test).shape)\n",
    "print(np.array(y_train).shape)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Input, Model\n",
    "from keras.layers import Dropout, Dense\n",
    "from keras import optimizers\n",
    "\n",
    "input_tensor = Input(X_train.shape[1:])\n",
    "x = input_tensor\n",
    "#x = Dense(1536, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(input_tensor, x)\n",
    "\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'keras.utils.visualize_util'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-630ba6818c18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSVG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mSVG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'keras.utils.visualize_util'"
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot, plot\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leechan/anaconda3/envs/DLCNN/lib/python3.5/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "20000/20000 [==============================] - 2s 94us/step - loss: 0.0756 - acc: 0.9861 - val_loss: 0.0264 - val_acc: 0.9926\n",
      "Epoch 2/30\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0216 - acc: 0.9942 - val_loss: 0.0180 - val_acc: 0.9946\n",
      "Epoch 3/30\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0170 - acc: 0.9946 - val_loss: 0.0157 - val_acc: 0.9942\n",
      "Epoch 4/30\n",
      "20000/20000 [==============================] - 1s 30us/step - loss: 0.0152 - acc: 0.9952 - val_loss: 0.0151 - val_acc: 0.9946\n",
      "Epoch 5/30\n",
      "20000/20000 [==============================] - 1s 31us/step - loss: 0.0136 - acc: 0.9958 - val_loss: 0.0149 - val_acc: 0.9950\n",
      "Epoch 6/30\n",
      "20000/20000 [==============================] - 1s 30us/step - loss: 0.0126 - acc: 0.9961 - val_loss: 0.0149 - val_acc: 0.9944\n",
      "Epoch 7/30\n",
      "20000/20000 [==============================] - 1s 30us/step - loss: 0.0119 - acc: 0.9959 - val_loss: 0.0147 - val_acc: 0.9952\n",
      "Epoch 8/30\n",
      "20000/20000 [==============================] - 1s 30us/step - loss: 0.0117 - acc: 0.9963 - val_loss: 0.0147 - val_acc: 0.9954\n",
      "Epoch 9/30\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0113 - acc: 0.9962 - val_loss: 0.0148 - val_acc: 0.9954\n",
      "Epoch 10/30\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0107 - acc: 0.9965 - val_loss: 0.0158 - val_acc: 0.9944\n",
      "Epoch 11/30\n",
      "20000/20000 [==============================] - 1s 30us/step - loss: 0.0101 - acc: 0.9967 - val_loss: 0.0149 - val_acc: 0.9956\n",
      "Epoch 12/30\n",
      "20000/20000 [==============================] - 1s 31us/step - loss: 0.0096 - acc: 0.9969 - val_loss: 0.0148 - val_acc: 0.9952\n",
      "Epoch 13/30\n",
      "20000/20000 [==============================] - 1s 29us/step - loss: 0.0085 - acc: 0.9976 - val_loss: 0.0150 - val_acc: 0.9950\n",
      "Epoch 14/30\n",
      "20000/20000 [==============================] - 1s 30us/step - loss: 0.0094 - acc: 0.9970 - val_loss: 0.0151 - val_acc: 0.9948\n",
      "Epoch 15/30\n",
      "20000/20000 [==============================] - 1s 31us/step - loss: 0.0081 - acc: 0.9977 - val_loss: 0.0181 - val_acc: 0.9942\n",
      "Epoch 16/30\n",
      "20000/20000 [==============================] - 1s 29us/step - loss: 0.0080 - acc: 0.9976 - val_loss: 0.0151 - val_acc: 0.9952\n",
      "Epoch 17/30\n",
      "20000/20000 [==============================] - 1s 31us/step - loss: 0.0073 - acc: 0.9976 - val_loss: 0.0151 - val_acc: 0.9950\n",
      "Epoch 18/30\n",
      "20000/20000 [==============================] - 1s 31us/step - loss: 0.0075 - acc: 0.9976 - val_loss: 0.0164 - val_acc: 0.9948\n",
      "Epoch 19/30\n",
      "20000/20000 [==============================] - 1s 30us/step - loss: 0.0081 - acc: 0.9975 - val_loss: 0.0159 - val_acc: 0.9952\n",
      "Epoch 20/30\n",
      "20000/20000 [==============================] - 1s 33us/step - loss: 0.0073 - acc: 0.9975 - val_loss: 0.0157 - val_acc: 0.9950\n",
      "Epoch 21/30\n",
      "20000/20000 [==============================] - 1s 30us/step - loss: 0.0069 - acc: 0.9981 - val_loss: 0.0158 - val_acc: 0.9950\n",
      "Epoch 22/30\n",
      "20000/20000 [==============================] - 1s 31us/step - loss: 0.0066 - acc: 0.9976 - val_loss: 0.0166 - val_acc: 0.9948\n",
      "Epoch 23/30\n",
      "20000/20000 [==============================] - 1s 32us/step - loss: 0.0066 - acc: 0.9981 - val_loss: 0.0159 - val_acc: 0.9950\n",
      "Epoch 24/30\n",
      "20000/20000 [==============================] - 1s 32us/step - loss: 0.0066 - acc: 0.9979 - val_loss: 0.0167 - val_acc: 0.9952\n",
      "Epoch 25/30\n",
      "20000/20000 [==============================] - 1s 30us/step - loss: 0.0055 - acc: 0.9985 - val_loss: 0.0174 - val_acc: 0.9950\n",
      "Epoch 26/30\n",
      "20000/20000 [==============================] - 1s 30us/step - loss: 0.0060 - acc: 0.9981 - val_loss: 0.0163 - val_acc: 0.9950\n",
      "Epoch 27/30\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0055 - acc: 0.9983 - val_loss: 0.0173 - val_acc: 0.9948\n",
      "Epoch 28/30\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.0167 - val_acc: 0.9950\n",
      "Epoch 29/30\n",
      "20000/20000 [==============================] - 1s 31us/step - loss: 0.0056 - acc: 0.9985 - val_loss: 0.0169 - val_acc: 0.9950\n",
      "Epoch 30/30\n",
      "20000/20000 [==============================] - 1s 31us/step - loss: 0.0059 - acc: 0.9981 - val_loss: 0.0166 - val_acc: 0.9950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7375892e10>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, nb_epoch=30, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
